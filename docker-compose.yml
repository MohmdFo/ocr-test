services:
  # FastAPI OCR Service
  fastapi_app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: aip-ocr-api
    ports:
      - "8500:8000"
    environment:
      - LOG_LEVEL=INFO
      - ENABLE_FILE_LOGGING=false
      - DOTS_OCR_URL=http://dots-ocr:8000
    volumes:
      - uploads:/tmp/uploads
    depends_on:
      - dots-ocr
    networks:
      - ocr-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Dots OCR Service
  dots-ocr:
    build:
      context: ./dots-ocr
      dockerfile: docker/Dockerfile
    container_name: dots-ocr-service
    ports:
      - "8501:8000"  # Map to different port to avoid conflicts
    volumes:
      # Mount model directory (you need to download the model first)
      # Model URL: https://www.modelscope.cn/models/rednote-hilab/dots.ocr
      - ./models/dots.ocr:/workspace/weights/DotsOCR
    environment:
      - LOG_LEVEL=INFO
      - MODEL_PATH=/app/models
      - PYTHONPATH=/workspace/weights:$PYTHONPATH
    # GPU configuration (uncomment if you have GPU available)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - capabilities: [gpu]
    #           device_ids: ['0']
    networks:
      - ocr-network
    restart: unless-stopped
    # Custom entrypoint to match dots.ocr requirements
    entrypoint: /bin/bash
    command:
      - -c
      - |
        set -ex;
        echo '--- Starting dots.ocr server ---';
        echo 'Checking for model files...';
        if [ ! -d "/workspace/weights/DotsOCR" ] || [ -z "$(ls -A /workspace/weights/DotsOCR)" ]; then
          echo "ERROR: Model files not found in /workspace/weights/DotsOCR";
          echo "Please download the model from: https://www.modelscope.cn/models/rednote-hilab/dots.ocr";
          echo "And place it in ./models/dots.ocr directory";
          exit 1;
        fi;
        echo 'Modifying vllm entrypoint...';
        sed -i '/^from vllm\.entrypoints\.cli\.main import main/a from DotsOCR import modeling_dots_ocr_vllm' $(which vllm) && \
        echo 'Starting server...';
        exec vllm serve /workspace/weights/DotsOCR \
            --tensor-parallel-size 1 \
            --gpu-memory-utilization 0.8 \
            --chat-template-content-format string \
            --served-model-name dotsocr-model \
            --trust-remote-code \
            --host 0.0.0.0 \
            --port 8000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s  # OCR service might take longer to start

  # Optional: Redis for caching (if needed)
  redis:
    image: redis:7-alpine
    container_name: ocr-redis
    ports:
      - "6380:6379"  # Changed to avoid conflict with existing Redis on 6379
    volumes:
      - redis_data:/data
    networks:
      - ocr-network
    restart: unless-stopped
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 5s
      retries: 3

  # Optional: PostgreSQL for storing OCR results/metadata
  postgres:
    image: postgres:15-alpine
    container_name: ocr-postgres
    ports:
      - "5433:5432"  # Changed to avoid conflict with existing PostgreSQL on 5432
    environment:
      - POSTGRES_DB=ocr_db
      - POSTGRES_USER=ocr_user
      - POSTGRES_PASSWORD=ocr_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - ocr-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ocr_user -d ocr_db"]
      interval: 30s
      timeout: 5s
      retries: 3

volumes:
  uploads:
    driver: local
  models:
    driver: local
  ocr_cache:
    driver: local
  redis_data:
    driver: local
  postgres_data:
    driver: local

networks:
  ocr-network:
    driver: bridge
